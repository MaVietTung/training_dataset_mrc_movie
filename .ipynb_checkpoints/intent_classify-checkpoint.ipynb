{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from custom_model import LSTM_fixed_len\n",
    "from train import *\n",
    "from utils import ReviewsDataset\n",
    "from sklearn.utils import class_weight\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/taindp/Personal/text_classifcation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'\n",
    "model_path = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = pd.read_csv(os.path.join(data_path,'question_livestream_label.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em hỏi về ngành kỹ thuật hoá học và cơ hội...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>3</td>\n",
       "      <td>cho em xin giới thiệu về ngành kỹ thuật robot ạ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>3</td>\n",
       "      <td>ngành khoa học máy tính sau này ra làm công vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>em muốn học tự động hoá thì tương lai sẽ có ng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>3</td>\n",
       "      <td>dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            content\n",
       "0        1  thầy cho em hỏi nếu mình đã trúng tuyển chương...\n",
       "1        0  cho em hỏi em có thể đăng kí 2 ngành được khôn...\n",
       "2        1  cho em hỏi chương trình chất lượng cao ở bách ...\n",
       "3        1  cho em hỏi nếu em đã trúng tuyển chương trình ...\n",
       "4        0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...\n",
       "..     ...                                                ...\n",
       "428      3  cho em hỏi về ngành kỹ thuật hoá học và cơ hội...\n",
       "429      3    cho em xin giới thiệu về ngành kỹ thuật robot ạ\n",
       "430      3  ngành khoa học máy tính sau này ra làm công vi...\n",
       "431      3  em muốn học tự động hoá thì tương lai sẽ có ng...\n",
       "432      3  dạ cho em hỏi về đầu ra và cơ hội nghề nghiệp ...\n",
       "\n",
       "[433 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question['length'] = [len(item) for item in list(question['content'])]\n",
    "question['num_word'] = [len(item.split(' ')) for item in list(question['content'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.02540415704388"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(question['num_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 97., 169.,  86.,  48.,  25.,   4.,   3.,   0.,   0.,   1.]),\n",
       " array([ 6. , 11.6, 17.2, 22.8, 28.4, 34. , 39.6, 45.2, 50.8, 56.4, 62. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(question['num_word']), bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    list_token = ViTokenizer.tokenize(text)\n",
    "    return list_token.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for index, row in question.iterrows():\n",
    "    counts.update(tokenize(row['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words before: 616\n",
      "num_words after: 365\n"
     ]
    }
   ],
   "source": [
    "#deleting infrequent words\n",
    "print(\"num_words before:\",len(counts.keys()))\n",
    "for word in list(counts):\n",
    "    if counts[word] < 2:\n",
    "        del counts[word]\n",
    "print(\"num_words after:\",len(counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=75):\n",
    "    tokenized = tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "#     print(len(enc1))\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "#     print(len(encoded))\n",
    "    return [encoded]\n",
    "#     return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>length</th>\n",
       "      <th>num_word</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>thầy cho em hỏi nếu mình đã trúng tuyển chương...</td>\n",
       "      <td>159</td>\n",
       "      <td>33</td>\n",
       "      <td>[[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cho em hỏi em có thể đăng kí 2 ngành được khôn...</td>\n",
       "      <td>137</td>\n",
       "      <td>33</td>\n",
       "      <td>[[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi chương trình chất lượng cao ở bách ...</td>\n",
       "      <td>106</td>\n",
       "      <td>24</td>\n",
       "      <td>[[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cho em hỏi nếu em đã trúng tuyển chương trình ...</td>\n",
       "      <td>148</td>\n",
       "      <td>31</td>\n",
       "      <td>[[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...</td>\n",
       "      <td>273</td>\n",
       "      <td>62</td>\n",
       "      <td>[[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            content  length  num_word  \\\n",
       "0      1  thầy cho em hỏi nếu mình đã trúng tuyển chương...     159        33   \n",
       "1      0  cho em hỏi em có thể đăng kí 2 ngành được khôn...     137        33   \n",
       "2      1  cho em hỏi chương trình chất lượng cao ở bách ...     106        24   \n",
       "3      1  cho em hỏi nếu em đã trúng tuyển chương trình ...     148        31   \n",
       "4      0  thầy ơi cho em hỏi ví dụ nếu mình chọn nguyện ...     273        62   \n",
       "\n",
       "                                             encoded  \n",
       "0  [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, ...  \n",
       "1  [[3, 4, 5, 4, 13, 25, 26, 27, 22, 23, 4, 25, 2...  \n",
       "2  [[3, 4, 5, 10, 16, 17, 32, 33, 34, 22, 35, 36,...  \n",
       "3  [[3, 4, 5, 6, 4, 8, 9, 10, 11, 12, 4, 13, 40, ...  \n",
       "4  [[2, 41, 3, 4, 5, 42, 6, 7, 43, 44, 45, 46, 47...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 30\n",
    "question['encoded'] = question['content'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(question['encoded'])\n",
    "y = list(question['label'])\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=(1-0.693))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taindp/opt/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0, 1, 2, 3], y=[1, 1, 0, 2, 3, 2, 1, 3, 0, 1, 3, 0, 0, 3, 1, 1, 2, 0, 0, 2, 0, 3, 0, 3, 1, 3, 1, 2, 1, 2, 3, 0, 2, 2, 0, 3, 3, 3, 3, 0, 0, 0, 0, 3, 2, 2, 1, 1, 2, 0, 2, 2, 2, 2, 1, 2, 1, 1, 2, 0, 1, 0, 2, 0, 2, 3, 2, 3, 3, 2, 3, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 2, 3, 3, 2, 0, 0, 0, 3, 1, 1, 3, 3, 2, 2, 3, 3, 1, 2, 2, 1, 1, 2, 3, 0, 2, 3, 2, 0, 0, 3, 3, 0, 0, 3, 1, 2, 2, 0, 3, 0, 1, 1, 2, 2, 1, 3, 1, 2, 0, 3, 2, 1, 3, 0, 3, 1, 2, 2, 1, 3, 3, 0, 3, 2, 2, 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 0, 3, 2, 1, 0, 3, 3, 1, 2, 2, 2, 0, 0, 0, 0, 2, 3, 2, 2, 3, 3, 0, 2, 0, 2, 3, 0, 0, 3, 3, 2, 3, 2, 2, 2, 2, 3, 1, 3, 3, 3, 3, 2, 3, 3, 2, 3, 3, 2, 3, 1, 2, 2, 0, 0, 3, 1, 3, 2, 3, 1, 1, 3, 1, 1, 2, 2, 2, 3, 3, 1, 3, 3, 2, 3, 3, 3, 0, 3, 1, 0, 1, 3, 3, 3, 3, 1, 3, 2, 2, 0, 0, 1, 3, 2, 3, 1, 1, 3, 0, 3, 2, 3, 3, 2, 2, 0, 3, 2, 3, 2, 0, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 1, 2, 1, 0, 3, 3, 3, 0, 3, 1, 0, 3, 1, 3, 0, 2, 1, 3, 3, 2, 3, 0, 2, 3, 1, 3, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 0, 3, 3, 1, 2, 2, 2, 2, 3] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.4464, 1.3500, 0.8617, 0.7105])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_weights = class_weight.compute_class_weight('balanced',np.unique(y).tolist(),y)\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train).tolist(),y_train)\n",
    "class_weights = torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(X_train, y_train)\n",
    "valid_ds = ReviewsDataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "vocab_size = len(words)\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_fixed_len(\n",
       "  (embeddings): Embedding(367, 400, padding_idx=0)\n",
       "  (lstm): LSTM(400, 100, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc1): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fixed =  LSTM_fixed_len(\n",
    "                           vocab_size = vocab_size,\\\n",
    "                           embedding_dim = 400,\\\n",
    "                           hidden_dim = 100,\\\n",
    "                           num_layers = 2, \\\n",
    "                           bidirectional=True,\\\n",
    "                           dropout=0.5,\\\n",
    "                           n_class = class_weights.shape[0])\n",
    "model_fixed.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_fixed.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0 lr: 0.01\n",
      "\tTrain Loss: 1.508 | Valid Loss: 1.242\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.04      0.06        56\n",
      "           1       0.45      0.38      0.41        60\n",
      "           2       0.47      1.00      0.64        94\n",
      "           3       0.86      0.43      0.57       114\n",
      "\n",
      "    accuracy                           0.52       324\n",
      "   macro avg       0.48      0.46      0.42       324\n",
      "weighted avg       0.54      0.52      0.47       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.03      0.05        31\n",
      "           1       0.31      0.25      0.28        16\n",
      "           2       0.35      1.00      0.51        28\n",
      "           3       0.89      0.24      0.37        34\n",
      "\n",
      "    accuracy                           0.38       109\n",
      "   macro avg       0.43      0.38      0.30       109\n",
      "weighted avg       0.46      0.38      0.30       109\n",
      "\n",
      "Epoch-1 lr: 0.01\n",
      "\tTrain Loss: 1.213 | Valid Loss: 0.970\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04        56\n",
      "           1       0.83      0.88      0.85        60\n",
      "           2       0.65      0.94      0.77        94\n",
      "           3       0.86      0.94      0.90       114\n",
      "\n",
      "    accuracy                           0.77       324\n",
      "   macro avg       0.84      0.69      0.64       324\n",
      "weighted avg       0.82      0.77      0.70       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.03      0.06        31\n",
      "           1       0.58      0.88      0.70        16\n",
      "           2       0.55      0.93      0.69        28\n",
      "           3       0.72      0.76      0.74        34\n",
      "\n",
      "    accuracy                           0.61       109\n",
      "   macro avg       0.59      0.65      0.55       109\n",
      "weighted avg       0.60      0.61      0.53       109\n",
      "\n",
      "Epoch-2 lr: 0.01\n",
      "\tTrain Loss: 1.104 | Valid Loss: 0.883\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.59      0.55        56\n",
      "           1       0.77      0.92      0.84        60\n",
      "           2       0.94      0.68      0.79        94\n",
      "           3       0.89      0.96      0.92       114\n",
      "\n",
      "    accuracy                           0.81       324\n",
      "   macro avg       0.78      0.79      0.78       324\n",
      "weighted avg       0.82      0.81      0.81       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.29      0.36        31\n",
      "           1       0.62      1.00      0.76        16\n",
      "           2       0.62      0.57      0.59        28\n",
      "           3       0.82      0.91      0.86        34\n",
      "\n",
      "    accuracy                           0.66       109\n",
      "   macro avg       0.63      0.69      0.64       109\n",
      "weighted avg       0.64      0.66      0.64       109\n",
      "\n",
      "Epoch-3 lr: 0.01\n",
      "\tTrain Loss: 0.929 | Valid Loss: 0.881\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.54      0.66        56\n",
      "           1       0.96      0.90      0.93        60\n",
      "           2       0.80      0.96      0.87        94\n",
      "           3       0.93      0.98      0.96       114\n",
      "\n",
      "    accuracy                           0.88       324\n",
      "   macro avg       0.89      0.84      0.85       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.19      0.31        31\n",
      "           1       0.87      0.81      0.84        16\n",
      "           2       0.63      0.93      0.75        28\n",
      "           3       0.76      1.00      0.86        34\n",
      "\n",
      "    accuracy                           0.72       109\n",
      "   macro avg       0.75      0.73      0.69       109\n",
      "weighted avg       0.74      0.72      0.67       109\n",
      "\n",
      "Epoch-4 lr: 0.01\n",
      "\tTrain Loss: 0.856 | Valid Loss: 0.777\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80        56\n",
      "           1       0.95      0.93      0.94        60\n",
      "           2       0.97      0.83      0.90        94\n",
      "           3       0.97      0.98      0.97       114\n",
      "\n",
      "    accuracy                           0.91       324\n",
      "   macro avg       0.90      0.91      0.90       324\n",
      "weighted avg       0.92      0.91      0.92       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.55      0.62        31\n",
      "           1       0.75      0.94      0.83        16\n",
      "           2       0.77      0.71      0.74        28\n",
      "           3       0.87      1.00      0.93        34\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.77      0.80      0.78       109\n",
      "weighted avg       0.78      0.79      0.78       109\n",
      "\n",
      "Epoch-5 lr: 0.004\n",
      "\tTrain Loss: 0.649 | Valid Loss: 0.752\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89        56\n",
      "           1       0.98      0.97      0.97        60\n",
      "           2       0.97      0.93      0.95        94\n",
      "           3       0.97      0.99      0.98       114\n",
      "\n",
      "    accuracy                           0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.95      0.95      0.95       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.52      0.63        31\n",
      "           1       0.83      0.94      0.88        16\n",
      "           2       0.80      0.86      0.83        28\n",
      "           3       0.83      1.00      0.91        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.82      0.83      0.81       109\n",
      "weighted avg       0.81      0.82      0.80       109\n",
      "\n",
      "Epoch-6 lr: 0.004\n",
      "\tTrain Loss: 0.642 | Valid Loss: 0.760\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        56\n",
      "           1       0.97      0.97      0.97        60\n",
      "           2       0.97      0.95      0.96        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.96       324\n",
      "   macro avg       0.95      0.96      0.96       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.55      0.67        31\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       0.79      0.93      0.85        28\n",
      "           3       0.87      1.00      0.93        34\n",
      "\n",
      "    accuracy                           0.84       109\n",
      "   macro avg       0.85      0.85      0.84       109\n",
      "weighted avg       0.85      0.84      0.83       109\n",
      "\n",
      "Epoch-7 lr: 0.004\n",
      "\tTrain Loss: 0.552 | Valid Loss: 0.861\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91        56\n",
      "           1       0.98      0.95      0.97        60\n",
      "           2       0.99      0.95      0.97        94\n",
      "           3       0.97      0.99      0.98       114\n",
      "\n",
      "    accuracy                           0.96       324\n",
      "   macro avg       0.96      0.96      0.96       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.48      0.60        31\n",
      "           1       0.83      0.94      0.88        16\n",
      "           2       0.76      0.93      0.84        28\n",
      "           3       0.87      0.97      0.92        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.81      0.83      0.81       109\n",
      "weighted avg       0.81      0.82      0.80       109\n",
      "\n",
      "Epoch-8 lr: 0.004\n",
      "\tTrain Loss: 0.558 | Valid Loss: 0.935\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        56\n",
      "           1       0.91      0.98      0.94        60\n",
      "           2       1.00      0.95      0.97        94\n",
      "           3       1.00      0.96      0.98       114\n",
      "\n",
      "    accuracy                           0.96       324\n",
      "   macro avg       0.95      0.96      0.96       324\n",
      "weighted avg       0.97      0.96      0.96       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.48      0.59        31\n",
      "           1       0.55      1.00      0.71        16\n",
      "           2       0.79      0.93      0.85        28\n",
      "           3       0.96      0.76      0.85        34\n",
      "\n",
      "    accuracy                           0.76       109\n",
      "   macro avg       0.76      0.79      0.75       109\n",
      "weighted avg       0.80      0.76      0.76       109\n",
      "\n",
      "Epoch-9 lr: 0.004\n",
      "\tTrain Loss: 0.575 | Valid Loss: 0.930\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.97      0.99      0.98        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.98       324\n",
      "   macro avg       0.98      0.98      0.98       324\n",
      "weighted avg       0.98      0.98      0.98       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.55      0.65        31\n",
      "           1       0.68      0.94      0.79        16\n",
      "           2       0.73      0.86      0.79        28\n",
      "           3       0.97      0.94      0.96        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.80      0.82      0.80       109\n",
      "weighted avg       0.82      0.81      0.80       109\n",
      "\n",
      "Epoch-10 lr: 0.0016\n",
      "\tTrain Loss: 0.505 | Valid Loss: 1.011\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.45      0.61        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.93      0.83        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.82      0.84      0.80       109\n",
      "weighted avg       0.84      0.82      0.80       109\n",
      "\n",
      "Epoch-11 lr: 0.0016\n",
      "\tTrain Loss: 0.503 | Valid Loss: 1.043\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.67      1.00      0.80        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.91      0.94      0.93        34\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.80      0.82      0.78       109\n",
      "weighted avg       0.82      0.80      0.78       109\n",
      "\n",
      "Epoch-12 lr: 0.0016\n",
      "\tTrain Loss: 0.531 | Valid Loss: 1.039\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      1.00      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.67      1.00      0.80        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.91      0.94      0.93        34\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.80      0.82      0.78       109\n",
      "weighted avg       0.82      0.80      0.78       109\n",
      "\n",
      "Epoch-13 lr: 0.0016\n",
      "\tTrain Loss: 0.473 | Valid Loss: 1.082\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.98      1.00      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.98      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.57        31\n",
      "           1       0.67      1.00      0.80        16\n",
      "           2       0.71      0.89      0.79        28\n",
      "           3       0.91      0.94      0.93        34\n",
      "\n",
      "    accuracy                           0.79       109\n",
      "   macro avg       0.79      0.81      0.77       109\n",
      "weighted avg       0.81      0.79      0.77       109\n",
      "\n",
      "Epoch-14 lr: 0.0016\n",
      "\tTrain Loss: 0.499 | Valid Loss: 1.031\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.48      0.61        31\n",
      "           1       0.76      1.00      0.86        16\n",
      "           2       0.76      0.89      0.82        28\n",
      "           3       0.89      0.97      0.93        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.81      0.84      0.81       109\n",
      "weighted avg       0.82      0.82      0.80       109\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-15 lr: 0.00064\n",
      "\tTrain Loss: 0.451 | Valid Loss: 1.067\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.48      0.62        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.76      0.89      0.82        28\n",
      "           3       0.89      0.97      0.93        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.81      0.84      0.80       109\n",
      "weighted avg       0.83      0.82      0.80       109\n",
      "\n",
      "Epoch-16 lr: 0.00064\n",
      "\tTrain Loss: 0.500 | Valid Loss: 1.106\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.76      0.89      0.82        28\n",
      "           3       0.89      0.97      0.93        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.82      0.81      0.79       109\n",
      "\n",
      "Epoch-17 lr: 0.00064\n",
      "\tTrain Loss: 0.452 | Valid Loss: 1.119\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       0.99      0.99      0.99       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-18 lr: 0.00064\n",
      "\tTrain Loss: 0.489 | Valid Loss: 1.152\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.99      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.98      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-19 lr: 0.00064\n",
      "\tTrain Loss: 0.422 | Valid Loss: 1.157\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-20 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.497 | Valid Loss: 1.132\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-21 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.498 | Valid Loss: 1.140\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-22 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.399 | Valid Loss: 1.159\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.70      1.00      0.82        16\n",
      "           2       0.74      0.89      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.83      0.81      0.79       109\n",
      "\n",
      "Epoch-23 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.435 | Valid Loss: 1.180\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.74      0.93      0.83        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.82      0.84      0.80       109\n",
      "weighted avg       0.83      0.82      0.80       109\n",
      "\n",
      "Epoch-24 lr: 0.00025600000000000004\n",
      "\tTrain Loss: 0.469 | Valid Loss: 1.207\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.45      0.60        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.74      0.93      0.83        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.82       109\n",
      "   macro avg       0.82      0.84      0.80       109\n",
      "weighted avg       0.83      0.82      0.80       109\n",
      "\n",
      "Epoch-25 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.420 | Valid Loss: 1.219\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.57        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.72      0.93      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.82      0.81      0.79       109\n",
      "\n",
      "Epoch-26 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.425 | Valid Loss: 1.228\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      0.99      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.42      0.57        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.72      0.93      0.81        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.81       109\n",
      "   macro avg       0.81      0.83      0.79       109\n",
      "weighted avg       0.82      0.81      0.79       109\n",
      "\n",
      "Epoch-27 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.492 | Valid Loss: 1.243\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        56\n",
      "           1       1.00      0.98      0.99        60\n",
      "           2       1.00      0.99      0.99        94\n",
      "           3       1.00      1.00      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.39      0.53        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.70      0.93      0.80        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.80      0.82      0.78       109\n",
      "weighted avg       0.82      0.80      0.77       109\n",
      "\n",
      "Epoch-28 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.446 | Valid Loss: 1.253\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       1.00      0.98      0.99        60\n",
      "           2       0.99      1.00      0.99        94\n",
      "           3       1.00      1.00      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.39      0.53        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.70      0.93      0.80        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.80      0.82      0.78       109\n",
      "weighted avg       0.82      0.80      0.77       109\n",
      "\n",
      "Epoch-29 lr: 0.00010240000000000002\n",
      "\tTrain Loss: 0.431 | Valid Loss: 1.263\n",
      "==================================================\n",
      "==================================================\n",
      "classify report train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       1.00      0.98      0.99        60\n",
      "           2       0.99      1.00      0.99        94\n",
      "           3       1.00      1.00      1.00       114\n",
      "\n",
      "    accuracy                           0.99       324\n",
      "   macro avg       0.99      0.99      0.99       324\n",
      "weighted avg       0.99      0.99      0.99       324\n",
      "\n",
      "==================================================\n",
      "classify report valid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.39      0.53        31\n",
      "           1       0.73      1.00      0.84        16\n",
      "           2       0.70      0.93      0.80        28\n",
      "           3       0.92      0.97      0.94        34\n",
      "\n",
      "    accuracy                           0.80       109\n",
      "   macro avg       0.80      0.82      0.78       109\n",
      "weighted avg       0.82      0.80      0.77       109\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss=[]\n",
    "acc=[]\n",
    "val_loss=[]\n",
    "acc_max = 0\n",
    "\n",
    "valid_loss_min = 1.\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train_model(model_fixed,train_dl,optimizer,criterion,writer,epoch)\n",
    "    valid_loss = evaluate(model_fixed, val_dl,criterion)\n",
    "    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "    \n",
    "    if valid_loss < valid_loss_min:\n",
    "        valis_loss_min = valid_loss\n",
    "        checkpoint = {'model': model_fixed,\n",
    "          'state_dict': model_fixed.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()}\n",
    "        valis_loss_save = str(valis_loss_min).replace('.','_')[:3]\n",
    "        torch.save(checkpoint, os.path.join(model_path,'checkpoint_{}.pth'.format(valis_loss_save)))\n",
    "#     print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
    "    print('='*50)\n",
    "#     print('pred',pred)\n",
    "    loss.append(train_loss)\n",
    "#     acc.append(train_acc)\n",
    "    val_loss.append(valid_loss)\n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "        \n",
    "    list_pred_train = []\n",
    "    list_true_train = []\n",
    "    \n",
    "    for x,y in train_dl:\n",
    "        x = x.long()\n",
    "        pred = model_fixed(x)\n",
    "        for item in pred:\n",
    "            list_pred_train.append(item.argmax().item())\n",
    "        for true in y:\n",
    "            list_true_train.append(true.item())\n",
    "            \n",
    "    print('='*50)\n",
    "    print('classify report train')\n",
    "    \n",
    "    print(classification_report(list_true_train,list_pred_train))\n",
    "    \n",
    "    ## validation\n",
    "        \n",
    "    list_pred_valid = []\n",
    "    list_true_valid = []\n",
    "    \n",
    "    for x,y in val_dl:\n",
    "        x = x.long()\n",
    "        pred = model_fixed(x)\n",
    "        for item in pred:\n",
    "\n",
    "            list_pred_valid.append(item.argmax().item())\n",
    "        for true in y:\n",
    "            list_true_valid.append(true.item())\n",
    "            \n",
    "    print('='*50)\n",
    "    print('classify report valid')\n",
    "            \n",
    "    print(classification_report(list_true_valid,list_pred_valid))\n",
    "#     print(confusion_matrix(pred,list_true))\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'model': model_fixed,\n",
    "      'state_dict': model_fixed.state_dict(),\n",
    "      'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, os.path.join(model_path,'model_jun24.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pred = []\n",
    "list_true = []\n",
    "for x,y in val_dl:\n",
    "    x = x.long()\n",
    "    pred = model_fixed(x)\n",
    "    for item in pred:\n",
    "#         print(item.argmax())\n",
    "        list_pred.append(item.argmax().item())\n",
    "    for true in y:\n",
    "        list_true.append(true.item())\n",
    "#         print(true.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(list_pred,list_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(f1_score(list_true, list_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = load_checkpoint(os.path.join(model_path,'model_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = os.path.join(model_path,'model_intent.pth')\n",
    "# joblib.dump(load_model, filename)\n",
    "# # with open('vectorizer.pickle', 'wb') as handle:\n",
    "# #     pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = 'https://api-intent.herokuapp.com/predict'\n",
    "# pred = requests.post(url,json={'message':'ad cho em hỏi chương trình tiên tiến với chất lượng cao khác nhau thế nào ạ'})\n",
    "# print(pred.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in val_dl:\n",
    "#     print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(vocab2index,os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = torch.load(os.path.join(model_path,'vocab_apr7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sent = 'ad cho em hỏi ngành điện tử viễn thông có ổn không ạ'\n",
    "test_enc =  torch.from_numpy(encode_sentence(test_sent, vocab2index, N)[0].astype(np.float32))\n",
    "test_enc = torch.reshape(test_enc,(1,N))\n",
    "test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = load_model(test_enc.long())\n",
    "prop_preds = nn.functional.softmax(preds,dim=1)\n",
    "print(prop_preds)\n",
    "pred_label = prop_preds.argmax().item()\n",
    "pred_label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
